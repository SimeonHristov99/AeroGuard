{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/harshjain123/bert-for-everyone-tutorial-implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from controller import Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Controller('i01')\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = fr'{c.get_path_iteration()}/{c.iteration}_ss.pkl'\n",
    "selection_set = pd.read_pickle(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train.shape=(38655, 114)\n",
      "df_val.shape=(4295, 114)\n",
      "df_test.shape=(4773, 114)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACN_NUM_ACN</th>\n",
       "      <th>TIME_DATE</th>\n",
       "      <th>TIME_1_LOCAL_TIME_OF_DAY</th>\n",
       "      <th>PLACE_LOCALE_REFERENCE</th>\n",
       "      <th>PLACE_1_STATE_REFERENCE</th>\n",
       "      <th>PLACE_2_RELATIVE_POSITION_ANGLE_RADIAL</th>\n",
       "      <th>PLACE_3_RELATIVE_POSITION_DISTANCE_NAUTICAL_MILES</th>\n",
       "      <th>PLACE_4_ALTITUDE_AGL_SINGLE_VALUE</th>\n",
       "      <th>PLACE_5_ALTITUDE_MSL_SINGLE_VALUE</th>\n",
       "      <th>ENVIRONMENT_FLIGHT_CONDITIONS</th>\n",
       "      <th>...</th>\n",
       "      <th>ASSESSMENTS_CONTRIBUTING_FACTORS_SITUATIONS</th>\n",
       "      <th>ASSESSMENTS_1_PRIMARY_PROBLEM</th>\n",
       "      <th>REPORT_1_NARRATIVE</th>\n",
       "      <th>REPORT_1_1_CALLBACK</th>\n",
       "      <th>REPORT_2_NARRATIVE</th>\n",
       "      <th>REPORT_2_1_CALLBACK</th>\n",
       "      <th>REPORT_1_2_SYNOPSIS</th>\n",
       "      <th>TRAIN_VAL_TEST_SPLIT</th>\n",
       "      <th>EVENT_RISK</th>\n",
       "      <th>EVENT_RISK_STR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1574675</td>\n",
       "      <td>201808</td>\n",
       "      <td>0601-1200</td>\n",
       "      <td>SNA.Airport</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>...</td>\n",
       "      <td>Human Factors</td>\n",
       "      <td>Human Factors</td>\n",
       "      <td>SNA RNP-Z to Runway 20R. The FMC was properly ...</td>\n",
       "      <td>NA</td>\n",
       "      <td>We were cleared for the RNP RNAV Z 20R Approac...</td>\n",
       "      <td>NA</td>\n",
       "      <td>B737-700 flight crew reported failing to make ...</td>\n",
       "      <td>Train</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1224894</td>\n",
       "      <td>201412</td>\n",
       "      <td>0601-1200</td>\n",
       "      <td>MSY.Airport</td>\n",
       "      <td>LA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VMC</td>\n",
       "      <td>...</td>\n",
       "      <td>Human Factors</td>\n",
       "      <td>Human Factors</td>\n",
       "      <td>On base to final turn to runway 1 in MSY at ap...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Captain reports sighting of a drone at 1;000 f...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0</td>\n",
       "      <td>Low risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1134202</td>\n",
       "      <td>201312</td>\n",
       "      <td>1201-1800</td>\n",
       "      <td>ZZZ.ARTCC</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>IMC</td>\n",
       "      <td>...</td>\n",
       "      <td>Human Factors; Aircraft; Procedure; Weather</td>\n",
       "      <td>Aircraft</td>\n",
       "      <td>I climbed to my filed altitude of 5;000 FT; an...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>SR22 pilot became disoriented on approach in I...</td>\n",
       "      <td>Train</td>\n",
       "      <td>3</td>\n",
       "      <td>Moderately high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1222074</td>\n",
       "      <td>201411</td>\n",
       "      <td>1201-1800</td>\n",
       "      <td>CWA.Airport</td>\n",
       "      <td>WI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>...</td>\n",
       "      <td>Aircraft</td>\n",
       "      <td>Aircraft</td>\n",
       "      <td>I had my pitot heat checked prior to winter an...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>BE58 pilot experiences pitot heat failure desc...</td>\n",
       "      <td>Train</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1733019</td>\n",
       "      <td>202003</td>\n",
       "      <td>1801-2400</td>\n",
       "      <td>ZDV.ARTCC</td>\n",
       "      <td>CO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>...</td>\n",
       "      <td>Airspace Structure; Weather</td>\n",
       "      <td>Weather</td>\n",
       "      <td>At 32000 ft. just north of PUB the aircraft ex...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>B737 First Officer reported unexpected moderat...</td>\n",
       "      <td>Train</td>\n",
       "      <td>3</td>\n",
       "      <td>Moderately high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47718</th>\n",
       "      <td>1341108</td>\n",
       "      <td>201603</td>\n",
       "      <td>0601-1200</td>\n",
       "      <td>ZZZ.Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IMC</td>\n",
       "      <td>...</td>\n",
       "      <td>Company Policy; Human Factors</td>\n",
       "      <td>Human Factors</td>\n",
       "      <td>We did an originator out of ZZZ and had a main...</td>\n",
       "      <td>NA</td>\n",
       "      <td>[Report narrative contained no additional info...</td>\n",
       "      <td>NA</td>\n",
       "      <td>CRJ-900 flight crew reported being dispatched ...</td>\n",
       "      <td>Test</td>\n",
       "      <td>3</td>\n",
       "      <td>Moderately high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47719</th>\n",
       "      <td>1087474</td>\n",
       "      <td>201305</td>\n",
       "      <td>1201-1800</td>\n",
       "      <td>PHX.Airport</td>\n",
       "      <td>AZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>VMC</td>\n",
       "      <td>...</td>\n",
       "      <td>Aircraft; Human Factors; Procedure</td>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>PHX takeoff Runway 25R flaps 5. CLEARANCE: MAX...</td>\n",
       "      <td>NA</td>\n",
       "      <td>There was an Airbus that departed before us an...</td>\n",
       "      <td>NA</td>\n",
       "      <td>CE750 flight crew departing PHX Runway 25R on ...</td>\n",
       "      <td>Test</td>\n",
       "      <td>3</td>\n",
       "      <td>Moderately high risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47720</th>\n",
       "      <td>1756601</td>\n",
       "      <td>202008</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>...</td>\n",
       "      <td>Environment - Non Weather Related; Company Pol...</td>\n",
       "      <td>Company Policy</td>\n",
       "      <td>I was scheduled to complete the one day traini...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Air carrier First Officer reported that re-qua...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0</td>\n",
       "      <td>Low risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47721</th>\n",
       "      <td>1102938</td>\n",
       "      <td>201307</td>\n",
       "      <td>0601-1200</td>\n",
       "      <td>MEM.Airport</td>\n",
       "      <td>TN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VMC</td>\n",
       "      <td>...</td>\n",
       "      <td>Airspace Structure; Chart Or Publication; Proc...</td>\n",
       "      <td>Human Factors</td>\n",
       "      <td>We departed Runway 36C in MEM via the GOETZ TW...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>On initial climb out via the GOETZ RNAV SID fr...</td>\n",
       "      <td>Test</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47722</th>\n",
       "      <td>1681426</td>\n",
       "      <td>201909</td>\n",
       "      <td>0001-0600</td>\n",
       "      <td>ZZZ.Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>...</td>\n",
       "      <td>Incorrect / Not Installed / Unavailable Part; ...</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>Walking to the aircraft; the inbound crew info...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>A319 Captain reported an incorrect MEL action ...</td>\n",
       "      <td>Test</td>\n",
       "      <td>1</td>\n",
       "      <td>Moderately medium risk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47723 rows Ã— 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ACN_NUM_ACN  TIME_DATE TIME_1_LOCAL_TIME_OF_DAY PLACE_LOCALE_REFERENCE  \\\n",
       "0          1574675     201808                0601-1200            SNA.Airport   \n",
       "1          1224894     201412                0601-1200            MSY.Airport   \n",
       "2          1134202     201312                1201-1800              ZZZ.ARTCC   \n",
       "3          1222074     201411                1201-1800            CWA.Airport   \n",
       "4          1733019     202003                1801-2400              ZDV.ARTCC   \n",
       "...            ...        ...                      ...                    ...   \n",
       "47718      1341108     201603                0601-1200            ZZZ.Airport   \n",
       "47719      1087474     201305                1201-1800            PHX.Airport   \n",
       "47720      1756601     202008                       NA                     NA   \n",
       "47721      1102938     201307                0601-1200            MEM.Airport   \n",
       "47722      1681426     201909                0001-0600            ZZZ.Airport   \n",
       "\n",
       "      PLACE_1_STATE_REFERENCE  PLACE_2_RELATIVE_POSITION_ANGLE_RADIAL  \\\n",
       "0                          CA                                     NaN   \n",
       "1                          LA                                     NaN   \n",
       "2                          US                                     NaN   \n",
       "3                          WI                                     NaN   \n",
       "4                          CO                                     NaN   \n",
       "...                       ...                                     ...   \n",
       "47718                      US                                     NaN   \n",
       "47719                      AZ                                     NaN   \n",
       "47720                      NA                                     NaN   \n",
       "47721                      TN                                     NaN   \n",
       "47722                      US                                     NaN   \n",
       "\n",
       "       PLACE_3_RELATIVE_POSITION_DISTANCE_NAUTICAL_MILES  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                   20.0   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "47718                                                NaN   \n",
       "47719                                                NaN   \n",
       "47720                                                NaN   \n",
       "47721                                                NaN   \n",
       "47722                                                NaN   \n",
       "\n",
       "       PLACE_4_ALTITUDE_AGL_SINGLE_VALUE  PLACE_5_ALTITUDE_MSL_SINGLE_VALUE  \\\n",
       "0                                    NaN                             5000.0   \n",
       "1                                 1000.0                                NaN   \n",
       "2                                    NaN                             2600.0   \n",
       "3                                    NaN                             4000.0   \n",
       "4                                    NaN                            32000.0   \n",
       "...                                  ...                                ...   \n",
       "47718                                NaN                                NaN   \n",
       "47719                                NaN                             8000.0   \n",
       "47720                                0.0                                NaN   \n",
       "47721                                NaN                                NaN   \n",
       "47722                                0.0                                NaN   \n",
       "\n",
       "      ENVIRONMENT_FLIGHT_CONDITIONS  ...  \\\n",
       "0                                NA  ...   \n",
       "1                               VMC  ...   \n",
       "2                               IMC  ...   \n",
       "3                                NA  ...   \n",
       "4                                NA  ...   \n",
       "...                             ...  ...   \n",
       "47718                           IMC  ...   \n",
       "47719                           VMC  ...   \n",
       "47720                            NA  ...   \n",
       "47721                           VMC  ...   \n",
       "47722                            NA  ...   \n",
       "\n",
       "             ASSESSMENTS_CONTRIBUTING_FACTORS_SITUATIONS  \\\n",
       "0                                          Human Factors   \n",
       "1                                          Human Factors   \n",
       "2            Human Factors; Aircraft; Procedure; Weather   \n",
       "3                                               Aircraft   \n",
       "4                            Airspace Structure; Weather   \n",
       "...                                                  ...   \n",
       "47718                      Company Policy; Human Factors   \n",
       "47719                 Aircraft; Human Factors; Procedure   \n",
       "47720  Environment - Non Weather Related; Company Pol...   \n",
       "47721  Airspace Structure; Chart Or Publication; Proc...   \n",
       "47722  Incorrect / Not Installed / Unavailable Part; ...   \n",
       "\n",
       "      ASSESSMENTS_1_PRIMARY_PROBLEM  \\\n",
       "0                     Human Factors   \n",
       "1                     Human Factors   \n",
       "2                          Aircraft   \n",
       "3                          Aircraft   \n",
       "4                           Weather   \n",
       "...                             ...   \n",
       "47718                 Human Factors   \n",
       "47719                     Ambiguous   \n",
       "47720                Company Policy   \n",
       "47721                 Human Factors   \n",
       "47722                     Procedure   \n",
       "\n",
       "                                      REPORT_1_NARRATIVE REPORT_1_1_CALLBACK  \\\n",
       "0      SNA RNP-Z to Runway 20R. The FMC was properly ...                  NA   \n",
       "1      On base to final turn to runway 1 in MSY at ap...                  NA   \n",
       "2      I climbed to my filed altitude of 5;000 FT; an...                  NA   \n",
       "3      I had my pitot heat checked prior to winter an...                  NA   \n",
       "4      At 32000 ft. just north of PUB the aircraft ex...                  NA   \n",
       "...                                                  ...                 ...   \n",
       "47718  We did an originator out of ZZZ and had a main...                  NA   \n",
       "47719  PHX takeoff Runway 25R flaps 5. CLEARANCE: MAX...                  NA   \n",
       "47720  I was scheduled to complete the one day traini...                  NA   \n",
       "47721  We departed Runway 36C in MEM via the GOETZ TW...                  NA   \n",
       "47722  Walking to the aircraft; the inbound crew info...                  NA   \n",
       "\n",
       "                                      REPORT_2_NARRATIVE REPORT_2_1_CALLBACK  \\\n",
       "0      We were cleared for the RNP RNAV Z 20R Approac...                  NA   \n",
       "1                                                     NA                  NA   \n",
       "2                                                     NA                  NA   \n",
       "3                                                     NA                  NA   \n",
       "4                                                     NA                  NA   \n",
       "...                                                  ...                 ...   \n",
       "47718  [Report narrative contained no additional info...                  NA   \n",
       "47719  There was an Airbus that departed before us an...                  NA   \n",
       "47720                                                 NA                  NA   \n",
       "47721                                                 NA                  NA   \n",
       "47722                                                 NA                  NA   \n",
       "\n",
       "                                     REPORT_1_2_SYNOPSIS TRAIN_VAL_TEST_SPLIT  \\\n",
       "0      B737-700 flight crew reported failing to make ...                Train   \n",
       "1      Captain reports sighting of a drone at 1;000 f...                Train   \n",
       "2      SR22 pilot became disoriented on approach in I...                Train   \n",
       "3      BE58 pilot experiences pitot heat failure desc...                Train   \n",
       "4      B737 First Officer reported unexpected moderat...                Train   \n",
       "...                                                  ...                  ...   \n",
       "47718  CRJ-900 flight crew reported being dispatched ...                 Test   \n",
       "47719  CE750 flight crew departing PHX Runway 25R on ...                 Test   \n",
       "47720  Air carrier First Officer reported that re-qua...                 Test   \n",
       "47721  On initial climb out via the GOETZ RNAV SID fr...                 Test   \n",
       "47722  A319 Captain reported an incorrect MEL action ...                 Test   \n",
       "\n",
       "      EVENT_RISK          EVENT_RISK_STR  \n",
       "0              2             Medium risk  \n",
       "1              0                Low risk  \n",
       "2              3    Moderately high risk  \n",
       "3              2             Medium risk  \n",
       "4              3    Moderately high risk  \n",
       "...          ...                     ...  \n",
       "47718          3    Moderately high risk  \n",
       "47719          3    Moderately high risk  \n",
       "47720          0                Low risk  \n",
       "47721          2             Medium risk  \n",
       "47722          1  Moderately medium risk  \n",
       "\n",
       "[47723 rows x 114 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = fr'{c.get_path_data_prepared()}/01_df_train_val_test.pkl'\n",
    "df_train_val_test = pd.read_pickle(filepath)\n",
    "\n",
    "df_train = df_train_val_test.query('TRAIN_VAL_TEST_SPLIT == \"Train\"')\n",
    "print(f'{df_train.shape=}')\n",
    "df_val = df_train_val_test.query('TRAIN_VAL_TEST_SPLIT == \"Validation\"')\n",
    "print(f'{df_val.shape=}')\n",
    "df_test = df_train_val_test.query('TRAIN_VAL_TEST_SPLIT == \"Test\"')\n",
    "print(f'{df_test.shape=}')\n",
    "\n",
    "df_train_val_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_text.shape=(38655,)\n",
      "train_labels.shape=(38655,)\n",
      "val_text.shape=(4295,)\n",
      "val_labels.shape=(4295,)\n",
      "test_text.shape=(4773,)\n",
      "test_labels.shape=(4773,)\n"
     ]
    }
   ],
   "source": [
    "train_text = df_train['REPORT_1_NARRATIVE']\n",
    "train_labels = df_train['EVENT_RISK']\n",
    "\n",
    "val_text = df_val['REPORT_1_NARRATIVE']\n",
    "val_labels = df_val['EVENT_RISK']\n",
    "\n",
    "test_text = df_test['REPORT_1_NARRATIVE']\n",
    "test_labels = df_test['EVENT_RISK']\n",
    "\n",
    "print(f'{train_text.shape=}')\n",
    "print(f'{train_labels.shape=}')\n",
    "print(f'{val_text.shape=}')\n",
    "print(f'{val_labels.shape=}')\n",
    "print(f'{test_text.shape=}')\n",
    "print(f'{test_labels.shape=}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get length of all the messages in the train set\n",
    "seq_len = [len(i.split()) for i in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize & Encode the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/Dev/AeroGuard/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens_train['input_ids'][0]))\n",
    "print(len(tokens_train['input_ids'][1]))\n",
    "print(len(tokens_train['input_ids'][2]))\n",
    "print(len(tokens_train['input_ids'][4]))\n",
    "print(len(tokens_train['input_ids'][6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensors\n",
    "\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a batch size\n",
    "batch_size = 32\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        \n",
    "        self.bert = bert \n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "      \n",
    "        # relu activation function\n",
    "        self.relu =  nn.ReLU()\n",
    "\n",
    "        # dense layer 1\n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "      \n",
    "        # dense layer 2 (Output layer)\n",
    "        self.fc2 = nn.Linear(512,5)\n",
    "\n",
    "        #softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "        \n",
    "        #pass the inputs to the model  \n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
    "      \n",
    "        x = self.fc1(cls_hs)\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # output layer\n",
    "        x = self.fc2(x)\n",
    "      \n",
    "        # apply softmax activation\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_weights=array([0.88770238, 1.65298268, 0.57706949, 1.30349014, 1.30129608])\n"
     ]
    }
   ],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert).to(device)\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(),lr = 1e-5) \n",
    "\n",
    "#compute the class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "print(f'{class_weights=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting list of class weights to a tensor\n",
    "weights= torch.tensor(class_weights,dtype=torch.float).to(device)\n",
    "\n",
    "# define the loss function\n",
    "cross_entropy = nn.NLLLoss(weight=weights) \n",
    "\n",
    "# number of training epochs\n",
    "epochs = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "    \n",
    "    model.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "    # empty list to save model predictions\n",
    "    total_preds=[]\n",
    "  \n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(train_dataloader):\n",
    "        \n",
    "        # progress update after every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "        \n",
    "        # push the batch to gpu\n",
    "        batch = [r.to(device) for r in batch]\n",
    " \n",
    "        sent_id, mask, labels = batch\n",
    "        \n",
    "        # clear previously calculated gradients \n",
    "        model.zero_grad()        \n",
    "\n",
    "        # get model predictions for the current batch\n",
    "        preds = model(sent_id, mask)\n",
    "\n",
    "        # compute the loss between actual and predicted values\n",
    "        loss = cross_entropy(preds, labels)\n",
    "\n",
    "        # add on to the total loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    # append the model predictions\n",
    "    total_preds.append(preds)\n",
    "\n",
    "    # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "  \n",
    "      # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "      # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    #returns the loss and predictions\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "    \n",
    "    print(\"\\nEvaluating...\")\n",
    "  \n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    \n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "\n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(val_dataloader):\n",
    "        \n",
    "        # Progress update every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            \n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [t.to(device) for t in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # model predictions\n",
    "            preds = model(sent_id, mask)\n",
    "\n",
    "            # compute the validation loss between actual and predicted values\n",
    "            loss = cross_entropy(preds,labels)\n",
    "\n",
    "            total_loss = total_loss + loss.item()\n",
    "\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "\n",
    "            total_preds.append(preds)\n",
    "\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 10\n",
      "  Batch    50  of  1,208.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_163170/2583630083.py\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_163170/713261506.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# get model predictions for the current batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# compute the loss between actual and predicted values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/AeroGuard/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_163170/1711689251.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent_id, mask)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#pass the inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_hs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_hs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/AeroGuard/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/AeroGuard/.venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m         )\n\u001b[0;32m-> 1020\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1021\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/AeroGuard/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/AeroGuard/.venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    608\u001b[0m                 )\n\u001b[1;32m    609\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    611\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/AeroGuard/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/AeroGuard/.venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    538\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         )\n",
      "\u001b[0;32m~/Dev/AeroGuard/.venv/lib/python3.10/site-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/AeroGuard/.venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/AeroGuard/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/AeroGuard/.venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/AeroGuard/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/AeroGuard/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
